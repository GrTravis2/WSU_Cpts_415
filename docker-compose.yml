services:
  master:
    build:
      context: .
      dockerfile: Dockerfile.master
    container_name: master
    ports:
      - "8080:8080" # for web view
      - "7077:7077" # spark nodes network
    environment:
      - SPARK_NO_DAEMONIZE=1       # sleep instead of terminate

  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    depends_on:
      - master
    environment:
      - SPARK_MASTER_URL=spark://master:7077
      - SPARK_WORKER_CORES=1    # assume 1 core
      - SPARK_WORKER_MEMORY=1G  # and 1Gb of RAM
      - SPARK_NO_DAEMONIZE=1       # sleep instead of terminate

  history:
    build:
      context: .
      dockerfile: Dockerfile.history
    container_name: history-server
    ports:
      - "18080:18080" # Spark History Server UI
    volumes:
      - spark-events:/tmp/spark-events # Mount a volume for event logs
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/tmp/spark-events
      - SPARK_NO_DAEMONIZE=1       # sleep instead of terminate

  mongodb:
    image: mongo:8-noble
    container_name: db
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db # persist mongodb data which is in /data/db by default!
volumes:
  spark-events:
  mongo_data:
